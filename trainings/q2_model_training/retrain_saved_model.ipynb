{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-10T22:59:35.900064300Z",
     "start_time": "2023-10-10T22:59:35.872999500Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append('../../')\n",
    "\n",
    "from datetime import date, datetime\n",
    "r_today = date.today().strftime(\"%y%m%d\")\n",
    "r_time = datetime.now().strftime(\"%H%M\")\n",
    "# dataset_seed = int(f'{r_today}{r_time}')\n",
    "dataset_seed = 2310091953\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "\n",
    "from src.hypermodels import *\n",
    "from src.utils  import *\n",
    "from src.dataset import *\n",
    "\n",
    "question_id = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "image_size = 224\n",
    "\n",
    "# duel_results_path = f'../../data/duel_results/duels_question_{question_id}'\n",
    "# image_file_dir = '../../data/Mapillary_data/Sample_web_green'\n",
    "# \n",
    "# print(f'Dataset Seed:{dataset_seed}') # For reproducibility, seed is defined using the date and time (e.g. 2021-01-01 12:30:15 -> seed = 20210101123015)\n",
    "\n",
    "# (x_train, y_train), (x_val, y_val), (x_test, y_test) = prepare_dataset(duel_results_path, \n",
    "#                                                                        image_file_dir, \n",
    "#                                                                        img_size=image_size,\n",
    "#                                                                        model_type='ranking',\n",
    "#                                                                        shuffle=True, \n",
    "#                                                                        shuffle_seed=dataset_seed)\n",
    "\n",
    "# Load from the saved numpy arrays\n",
    "x1_train,x2_train = np.load('../../data/Q2_Datasets_RandomShuffled_1/x_train.npy')\n",
    "x1_val,x2_val = np.load('../../data/Q2_Datasets_RandomShuffled_1/x_val.npy')\n",
    "x1_test,x2_test = np.load('../../data/Q2_Datasets_RandomShuffled_1/x_test.npy')\n",
    "\n",
    "y_train = np.load('../../data/Q2_Datasets_RandomShuffled_1/y_train.npy')\n",
    "y_val = np.load('../../data/Q2_Datasets_RandomShuffled_1/y_val.npy')\n",
    "y_test = np.load('../../data/Q2_Datasets_RandomShuffled_1/y_test.npy')\n",
    "\n",
    "x_train = [x1_train,x2_train]\n",
    "x_val = [x1_val,x2_val]\n",
    "del x1_train,x2_train,x1_val,x2_val"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T22:59:37.358206200Z",
     "start_time": "2023-10-10T22:59:35.886648100Z"
    }
   },
   "id": "fc38af198747ec17"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Siamese_Ranking_Network\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_26 (InputLayer)          [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " input_27 (InputLayer)          [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " Ranking_Network (Functional)   (None, 1)            22437153    ['input_26[0][0]',               \n",
      "                                                                  'input_27[0][0]']               \n",
      "                                                                                                  \n",
      " subtract_8 (Subtract)          (None, 1)            0           ['Ranking_Network[0][0]',        \n",
      "                                                                  'Ranking_Network[1][0]']        \n",
      "                                                                                                  \n",
      " Final_Activation_Output (Activ  (None, 1)           0           ['subtract_8[0][0]']             \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 22,437,153\n",
      "Trainable params: 9,491,905\n",
      "Non-trainable params: 12,945,248\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model, load_model, model_from_json\n",
    "\n",
    "# build the model using model architecture\n",
    "saved_model_dir = '../../trainings/q2_model_training/hypermodel_tuning/BayesianOptimization_2310101054/Model_8_Ranking_VGG19_BestValAcc0.7338'\n",
    "model_file_path = '../../trainings/q2_model_training/hypermodel_tuning/BayesianOptimization_2310101054/Model_8_Ranking_VGG19_BestValAcc0.7338/Siamese_Ranking_Network.keras'\n",
    "model_architecture_file_path = '../../trainings/q2_model_training/hypermodel_tuning/BayesianOptimization_2310101054/best_model_architecture_8.json'\n",
    "\n",
    "trained_model = load_model(model_file_path, compile=True)\n",
    "\n",
    "# load json and create model\n",
    "json_file = open(model_architecture_file_path, 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "\n",
    "untrained_model =  model_from_json(loaded_model_json)\n",
    "untrained_model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T23:01:18.896007500Z",
     "start_time": "2023-10-10T23:01:16.897574400Z"
    }
   },
   "id": "24713ef5780878d6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.7275 - accuracy: 0.5743"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "optimizers = {\n",
    "    'adam': Adam(learning_rate=0.00001),\n",
    "    'rmsprop': RMSprop(learning_rate=0.00001)\n",
    "}\n",
    "\n",
    "untrained_model.compile(loss='binary_crossentropy', optimizer=optimizers['rmsprop'], metrics=['accuracy'])\n",
    "\n",
    "model = untrained_model\n",
    "# model = trained_model\n",
    "\n",
    "history = model.fit(\n",
    "    x_train, \n",
    "    y_train,\n",
    "    batch_size=64,\n",
    "    epochs=50,\n",
    "    validation_data=(x_val, y_val),\n",
    "    callbacks=[EarlyStopping(monitor='val_accuracy', patience=5, verbose=1, mode='auto', restore_best_weights=True)]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-10-10T23:01:52.951823100Z"
    }
   },
   "id": "6dc9df94d810c92d"
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "outputs": [],
   "source": [
    "from src.utils import safe_save_training_results\n",
    "\n",
    "best_val_acc = max(history.history['val_accuracy'])\n",
    "save_dir = os.path.join(saved_model_dir, f'Retrain_BestValAcc{best_val_acc}')\n",
    "\n",
    "safe_save_training_results(hyperparams_dict=None,\n",
    "                           model=model,\n",
    "                           model_save_type='keras', \n",
    "                           history=history, \n",
    "                           his_save_type='csv', \n",
    "                           save_dir = save_dir,)\n",
    "\n",
    "# Save the plot\n",
    "plot_model_metrics(history, ['loss', 'accuracy'], save_dir=save_dir)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ad61b973a54eaaba"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "K.clear_session()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "eba0799d166eda76"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c292994ed8f4645d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
